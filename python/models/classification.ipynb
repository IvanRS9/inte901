{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23717/1663609162.py:36: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  train['is_holiday'] = train['date'].isin(us_holidays)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        alto       1.00      1.00      1.00     18243\n",
      "       medio       0.43      0.18      0.25        17\n",
      "\n",
      "    accuracy                           1.00     18260\n",
      "   macro avg       0.71      0.59      0.62     18260\n",
      "weighted avg       1.00      1.00      1.00     18260\n",
      "\n",
      "[[18239     4]\n",
      " [   14     3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import holidays\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Cargar el DataFrame desde el archivo CSV\n",
    "data_path = os.path.join(os.getcwd(), 'data')  # Ruta al directorio 'data'\n",
    "train = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "\n",
    "# Asegurarse de que la columna 'date' esté en formato datetime\n",
    "train['date'] = pd.to_datetime(train['date'], errors='coerce')\n",
    "\n",
    "# Asegurarse que solo hay un registro por fecha y artículo\n",
    "train = train.groupby(['date', 'item'], as_index=False)['sales'].sum()\n",
    "\n",
    "# Eliminar filas con fechas inválidas\n",
    "train = train.dropna(subset=['date'])\n",
    "\n",
    "# Definir las categorías de ventas\n",
    "bins = [0, 50, 100, float('inf')]\n",
    "labels = ['bajo', 'medio', 'alto']\n",
    "train['sales_category'] = pd.cut(train['sales'], bins=bins, labels=labels)\n",
    "\n",
    "# Extraer características de tiempo adicionales\n",
    "train['dayofweek'] = train['date'].dt.dayofweek\n",
    "train['month'] = train['date'].dt.month\n",
    "train['year'] = train['date'].dt.year\n",
    "train['dayofyear'] = train['date'].dt.dayofyear\n",
    "train['is_weekend'] = train['date'].dt.dayofweek >= 5\n",
    "\n",
    "# Agregar información sobre días festivos\n",
    "us_holidays = holidays.MEX(years=[2013, 2014, 2015, 2016, 2017])\n",
    "train['is_holiday'] = train['date'].isin(us_holidays)\n",
    "\n",
    "# Convertir booleanos a enteros\n",
    "train['is_weekend'] = train['is_weekend'].astype(int)\n",
    "train['is_holiday'] = train['is_holiday'].astype(int)\n",
    "\n",
    "# Crear variables dummy para la característica 'item'\n",
    "train = pd.get_dummies(train, columns=['item'], drop_first=True)\n",
    "\n",
    "# Codificar la característica de fecha como días desde una fecha de referencia\n",
    "date_min = train['date'].min()\n",
    "train['date'] = (train['date'] - date_min).dt.days\n",
    "\n",
    "# Crear interacciones entre características\n",
    "for col in train.columns:\n",
    "    if col.startswith('item_'):\n",
    "        train[f'date_{col}'] = train['date'] * train[col]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X = train.drop(columns=['sales', 'sales_category'])\n",
    "y = train['sales_category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entrenar un modelo de clasificación (RandomForestClassifier en este caso)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = best_clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Guardar el modelo en un best_clf.pkl y scaler en un scaler.pkl\n",
    "import joblib\n",
    "joblib.dump(best_clf, 'best_clf.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar el train.csv\n",
    "test = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "#eliminar todos los datos que no del store 1 dejando el date,store,item y sales\n",
    "test = test[test['store'] == 1]\n",
    "\n",
    "#guardar el pd en un csv\n",
    "test.to_csv(os.path.join(data_path, 'test_store1.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones de categoría de ventas: ['alto' 'alto' 'alto' 'alto' 'alto' 'alto' 'alto' 'alto' 'alto' 'alto']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23717/707317462.py:29: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  test_df['is_holiday'] = test_df['date'].isin(us_holidays)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Datos de prueba para predicción\n",
    "test = [\n",
    "  {'date': '2024-01-01', 'item': 1},\n",
    "  {'date': '2024-01-01', 'item': 2},\n",
    "  {'date': '2024-01-01', 'item': 3},\n",
    "  {'date': '2024-01-01', 'item': 4},\n",
    "  {'date': '2024-01-01', 'item': 5},\n",
    "  {'date': '2024-01-01', 'item': 6},\n",
    "  {'date': '2024-01-01', 'item': 7},\n",
    "  {'date': '2024-01-01', 'item': 8},\n",
    "  {'date': '2024-01-01', 'item': 9},\n",
    "  {'date': '2016-02-14', 'item': 4}\n",
    "]\n",
    "\n",
    "# Convertir a DataFrame\n",
    "test_df = pd.DataFrame(test)\n",
    "\n",
    "# Asegurarse de que la columna 'date' esté en formato datetime\n",
    "test_df['date'] = pd.to_datetime(test_df['date'], errors='coerce')\n",
    "\n",
    "# Extraer características de tiempo adicionales\n",
    "test_df['dayofweek'] = test_df['date'].dt.dayofweek\n",
    "test_df['month'] = test_df['date'].dt.month\n",
    "test_df['year'] = test_df['date'].dt.year\n",
    "test_df['dayofyear'] = test_df['date'].dt.dayofyear\n",
    "test_df['is_weekend'] = test_df['date'].dt.dayofweek >= 5\n",
    "\n",
    "# Agregar información sobre días festivos\n",
    "test_df['is_holiday'] = test_df['date'].isin(us_holidays)\n",
    "\n",
    "# Convertir booleanos a enteros\n",
    "test_df['is_weekend'] = test_df['is_weekend'].astype(int)\n",
    "test_df['is_holiday'] = test_df['is_holiday'].astype(int)\n",
    "\n",
    "# Crear variables dummy para la característica 'item'\n",
    "test_df = pd.get_dummies(test_df, columns=['item'], drop_first=True)\n",
    "\n",
    "# Codificar la característica de fecha como días desde una fecha de referencia\n",
    "test_df['date'] = (test_df['date'] - date_min).dt.days\n",
    "\n",
    "# Crear interacciones entre características\n",
    "for col in test_df.columns:\n",
    "    if col.startswith('item_'):\n",
    "        test_df[f'date_{col}'] = test_df['date'] * test_df[col]\n",
    "\n",
    "# Asegurarse de que las columnas en el conjunto de prueba coinciden con las del entrenamiento\n",
    "expected_columns = set(X_train.columns)\n",
    "current_columns = set(test_df.columns)\n",
    "missing_columns = expected_columns - current_columns\n",
    "\n",
    "for col in missing_columns:\n",
    "    test_df[col] = 0\n",
    "\n",
    "# Ordenar las columnas para que coincidan\n",
    "test_df = test_df[X_train.columns]\n",
    "\n",
    "# Escalar los datos de prueba\n",
    "test_df_scaled = scaler.transform(test_df)\n",
    "\n",
    "# Hacer predicciones con el mejor modelo encontrado\n",
    "test_predictions = best_clf.predict(test_df_scaled)\n",
    "\n",
    "# Mostrar las predicciones\n",
    "print(\"Predicciones de categoría de ventas:\", test_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
